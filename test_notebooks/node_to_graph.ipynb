{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import glob\n",
    "import os\n",
    "from ripser import Rips\n",
    "import matplotlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def node_to_graph(file_name='val', label_op='avg'):\n",
    "    # Load in node embeddings, node labels, subgraph\n",
    "    nodes = np.load(\"/notebooks/subgraphs/{}.npy\".format(file_name))\n",
    "    labels = json.load(open(\"/notebooks/example_data/toy-ppi-class_map.json\"))\n",
    "    with open(\"/notebooks/subgraphs/{}_graph.pkl\".format(file_name), 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "        \n",
    "    # Get subgraph node labels\n",
    "    graph_labels = []\n",
    "    for n in G.nodes():\n",
    "        graph_labels.append(labels[str(n)])\n",
    "        \n",
    "    # Generate graph embeddings and label\n",
    "    graph_embed_tda = np.mean(tda_features(nodes), axis=0)\n",
    "    graph_embed = np.mean(nodes, axis=0)\n",
    "    graph_labels = np.array(graph_labels)\n",
    "    if label_op == 'avg':\n",
    "        graph_labels = np.mean(graph_labels, axis=0)\n",
    "    elif label_op == 'sum':\n",
    "        graph_labels = np.sum(graph_labels, axis=0)\n",
    "    else:\n",
    "        graph_labels = np.sum(graph_labels, axis=0)\n",
    "        for i in range(graph_labels.shape[0]):\n",
    "            graph_labels[i] = min(graph_labels[i], 1)\n",
    "    return graph_embed, graph_embed_tda, graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tda_features(nodes):\n",
    "    # rips = Rips(maxdim=2)\n",
    "    feat_cols = ['feat-{}'.format(i) for i in range(nodes.shape[1])]\n",
    "    embeds = pd.DataFrame(nodes, columns=feat_cols)\n",
    "    rips = Rips()\n",
    "\n",
    "    # Transform\n",
    "    print(\"Generating rips barcodes... This may take a while.\")\n",
    "    diagrams = rips.fit_transform(embeds)\n",
    "    lifetime_dim0_pts = diagrams[0][:, 1] - diagrams[0][:, 0] \n",
    "    lifetime_dim1_pts = diagrams[1][:, 1] - diagrams[1][:, 0]\n",
    "\n",
    "    # Replace NaN in dim0\n",
    "    i = np.argwhere(~np.isfinite(lifetime_dim0_pts))\n",
    "    if (len(i) > 0):\n",
    "        print('Cleaning dim0...')\n",
    "        lifetime_dim0_pts[i] = lifetime_dim0_pts.min() # Set NaNs to lowest real value\n",
    "        lifetime_dim0_pts[i] = lifetime_dim0_pts.max() + 1.0 # Replace NaNs with largest value\n",
    "\n",
    "    # Replace NaN in dim0\n",
    "    i = np.argwhere(~np.isfinite(lifetime_dim1_pts))\n",
    "    if (len(i) > 0):\n",
    "        print('Cleaning dim1...')\n",
    "        lifetime_dim1_pts[i] = lifetime_dim1_pts.min() # Set NaNs to lowest real value\n",
    "        lifetime_dim1_pts[i] = lifetime_dim1_pts.max() + 1.0 # Replace NaNs with largest value\n",
    "        \n",
    "    # Concatenate tda features to embeds\n",
    "    embeds['birth_dim0'] = pd.Series(data=diagrams[0][:, 0])\n",
    "    embeds['lifetime_dim0'] = pd.Series(data=lifetime_dim0_pts)\n",
    "    embeds['birth_dim1'] = pd.Series(data=diagrams[1][:, 0])\n",
    "    embeds['lifetime_dim1'] = pd.Series(data=lifetime_dim1_pts)\n",
    "    # embeds['birth_dim2'] = pd.Series(data=diagrams[2][:, 0])\n",
    "    # embeds['lifetime_dim2'] = pd.Series(data=lifetime_dim2_pts)\n",
    "    embeds.fillna(embeds.max(axis=0), inplace=True)\n",
    "    print(embeds.isnull().values.any())\n",
    "    return embeds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_data(label_op='avg'):\n",
    "    data = []\n",
    "    data_tda = []\n",
    "    labels = []\n",
    "    files = glob.glob('/notebooks/subgraphs/' + '*.npy')\n",
    "    for f in files:\n",
    "        filepath, file_ = os.path.split(f)\n",
    "        file_name, _ = os.path.splitext(file_)\n",
    "        if 'graph_embeds' not in file_name and 'graph_labels' not in file_name:\n",
    "            graph_embed, graph_embed_tda, graph_labels = node_to_graph(file_name=file_name, label_op=label_op)\n",
    "            data.append(graph_embed)\n",
    "            data_tda.append(graph_embed_tda)\n",
    "            labels.append(graph_labels)\n",
    "    return np.array(data), np.array(data_tda), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n",
      "Generating rips barcodes... This may take a while.\n",
      "Cleaning dim0...\n",
      "False\n",
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n",
      "Generating rips barcodes... This may take a while.\n",
      "Cleaning dim0...\n",
      "False\n",
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n",
      "Generating rips barcodes... This may take a while.\n",
      "Cleaning dim0...\n",
      "False\n",
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n",
      "Generating rips barcodes... This may take a while.\n",
      "Cleaning dim0...\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "data, data_tda, labels = get_graph_data()\n",
    "# with open('/notebooks/subgraphs/graph_embeds.npy', 'wb') as f:\n",
    "#     np.save(f, data)\n",
    "# with open('/notebooks/subgraphs/graph_embeds_tda.npy', 'wb') as f:\n",
    "#     np.save(f, data_tda)\n",
    "# with open('/notebooks/subgraphs/graph_labels.npy', 'wb') as f:\n",
    "#     np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeds = np.load('/notebooks/subgraphs/graph_embeds.npy')\n",
    "embeds_tda = np.load('/notebooks/subgraphs/graph_embeds_tda.npy')\n",
    "labels = np.load('/notebooks/subgraphs/graph_labels.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
